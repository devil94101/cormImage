{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devil94101/cormImage/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSQhzEa_kGbt"
      },
      "source": [
        "**Fruit Classification - Deep Learning Approach**\n",
        " \n",
        "Corns have a wide variety around the World and it is difficult to differentiate them just by looking. It is not easy especially nowadays when there are a lot of varieties of each corn which differ very slightly with each other that even human eye can be confused.\n",
        " \n",
        "To solve this problem, machine learning and deep learning techniques can be very useful as the development in these techniques especially in the field of neural networks has been immense in the last decade.\n",
        " \n",
        "In this notebook, I will explore deep learning approaches which I will explore machine learning approaches in the other notebook. The dataset and problem has been taken from Kaggle. Here's the link for the same :\n",
        " \n",
        "https://www.kaggle.com/nahomy/cornimage?\n",
        " \n",
        "Approaches Explored :-\n",
        " \n",
        "1) Building convolutional layers along with maxpooling\n",
        " \n",
        "2) Partial model with transfer learning approach from VGG16 and then adding some extra convolutional layers along with maxpooling\n",
        " \n",
        "In the end, I will write what all things can be done later\n",
        " \n",
        "I used google colab since it gives a free GPU and allow us to use the drive repository.\n",
        " \n",
        "Dataset Properties\n",
        " \n",
        "Total number of files: 3839.\n",
        " \n",
        "Training set size: 3072 \n",
        " \n",
        "Test set size: 767\n",
        " \n",
        "Multi-corn set size: 103 \n",
        " \n",
        " \n",
        "Image size: 100x100 pixels.\n",
        " \n",
        "I have used kaggle to get dataset directly in notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_VzbK6CkVsJ"
      },
      "source": [
        "# Importing libraries\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3mnFi--kcFt"
      },
      "source": [
        "dir_ = '../input/cornimage/Color Images'  # storing dataset path into a variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vi4Bd7SkjoC"
      },
      "source": [
        "BATCH, IMG_SIZE, SEED = 32, (160, 160), 42  # Assing custom  batch_size, img_size, seed\n",
        "\n",
        "# Spliting dataset into training and testing data in batches\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(dir_,\n",
        "                                                              batch_size = BATCH, \n",
        "                                                              image_size = IMG_SIZE, \n",
        "                                                              shuffle = True,\n",
        "                                                              validation_split = .2, \n",
        "                                                              subset = 'training',\n",
        "                                                              seed = SEED)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(dir_,\n",
        "                                                              batch_size = BATCH, \n",
        "                                                              image_size = IMG_SIZE, \n",
        "                                                              shuffle = True,\n",
        "                                                              validation_split = .2, \n",
        "                                                              subset = 'validation',\n",
        "                                                              seed = SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opIAEb5kkoaM"
      },
      "source": [
        "# assining labels to a variable\n",
        "classes = train_ds.class_names\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atAhf-6VktL5"
      },
      "source": [
        "# visualizing first batch of training data\n",
        "for image, label in train_ds.take(1):\n",
        "    plt.figure(figsize = (30, 30))\n",
        "    for i in range(32):\n",
        "        plt.subplot(6, 6, i+1)\n",
        "        plt.imshow(image[i]/255.)\n",
        "        plt.axis('off')\n",
        "        plt.title(classes[label[i]])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t10p8s7XkzCN"
      },
      "source": [
        "# Building Model for data Preprocessing\n",
        "model_pre_pro = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.Resizing(60, 60),\n",
        "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdztA0AKk3GN"
      },
      "source": [
        "# Building Model for data Agumentation\n",
        "model_agu = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30sCBUQ2k67K"
      },
      "source": [
        "Approach 1 - Customized CNN\n",
        "\n",
        "Now, let us start with our first approach that is using a customized Convolutional Neural Networks. CNNs are amazing techniques that helps a neural network learn spatial and related features. Before CNNs came, spatial information was tough to get learnt into a neural network since all the data was fed in a flatten format. CNNs helps neural network to learn the relationships between varios areas of an image like Edges, eyes etc. The more futher deep the neural networl goes, the more complex features are learnt.\n",
        "\n",
        "Here, as approach 1, we will use 2 X 2 filters and increase the number of layers the deeper we go along with 2 X 2 maxpooling layer which chooses the maximum value at a certain area.\n",
        "\n",
        "We will use RELU activation function to remove linearity to learn complex features.\n",
        "\n",
        "We will use dropout regularization which chooses a node using a probability that we will define and it will help prevent overfitting the model.\n",
        "\n",
        "Finally, a softmax unit will be used to classify and find the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XAfrr-Jk8mU"
      },
      "source": [
        "# Building Customized CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(160, 160, 3)),\n",
        "    model_pre_pro,\n",
        "    model_agu,\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'), #input_shape=(160, 160, 3)),\n",
        "    tf.keras.layers.MaxPool2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(25, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(36, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(169, activation = 'sigmoid'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(119, activation = 'tanh'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(79, activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(49, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(4, activation = 'softmax'),\n",
        "])\n",
        "\n",
        "# Model Summary\n",
        "model.summary() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E8CAXb8lBe2"
      },
      "source": [
        "# Visualizing Customized CNN model\n",
        "tf.keras.utils.plot_model(model,'corn.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9u-_vp5lD0b"
      },
      "source": [
        "# Model Compliation\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfSDSSO_lHgt"
      },
      "source": [
        "\n",
        "# Training Model\n",
        "EPOCHS = 100\n",
        "hist = model.fit(train_ds, epochs = EPOCHS, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMbpf9yelKcb"
      },
      "source": [
        "# Training History\n",
        "model_df=pd.DataFrame(hist.history)\n",
        "model_df['epoch']=hist.epoch\n",
        "print(model_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxkVaNDylMn9"
      },
      "source": [
        "# Visualizing Training Accuracy\n",
        "plt.grid(True)\n",
        "plt.plot(model_df['epoch'],model_df['accuracy'],label='training accuracy')\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Epoch')\n",
        "plt.title('Training Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhRdU-EnlOaf"
      },
      "source": [
        "# Visualizing Training Loss\n",
        "plt.grid(True)\n",
        "plt.plot(model_df['epoch'],model_df['loss'],label='training loss', color = 'orange')\n",
        "plt.xlabel('Loss')\n",
        "plt.ylabel('Epoch')\n",
        "plt.title('Training Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmL1KPArlQPT"
      },
      "source": [
        "# Model Evaluatation\n",
        "test_loss, test_accuracy = model.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbHi3STKlSsV"
      },
      "source": [
        "# Printing Testing Accuracy and Loss\n",
        "print(f'Test Accuracy = {test_accuracy}\\nTest Loss = {test_loss}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kFBy8DxlUnZ"
      },
      "source": [
        "# Making multiple batches of test data into single batch\n",
        "num_batch=0\n",
        "img=[]\n",
        "label=[]\n",
        "for image_batch,label_batch in test_ds:\n",
        "    num_batch+=1\n",
        "    img.append(image_batch)\n",
        "    label.append(label_batch)\n",
        "print(num_batch)\n",
        "inputs=np.concatenate(img)\n",
        "targets=np.concatenate(label)\n",
        "print(inputs.shape)\n",
        "print(targets.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6-jDrBLlXPu"
      },
      "source": [
        "# Predicting Data\n",
        "pred = model.predict(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEmjVTX1lcPC"
      },
      "source": [
        "# Visualizing Predicted Data\n",
        "plt.figure(figsize = (15, 50))\n",
        "for i in range(100):\n",
        "    plt.subplot(20, 5, i+1)\n",
        "    pred_label = np.argmax(pred[i])\n",
        "    test_label = targets[i]\n",
        "    plt.imshow(inputs[i]/255.)\n",
        "    plt.axis('off')\n",
        "    if pred_label == test_label:\n",
        "        color = 'green'\n",
        "        plt.title('Correct classification',color=color)\n",
        "    else:\n",
        "        color = 'red'\n",
        "        plt.title('WRONG classification',color=color)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQVYmK4klfMn"
      },
      "source": [
        "# Confusion Matrix of Predicted Data and Actual Data\n",
        "tf.math.confusion_matrix([np.argmax(i) for i in pred], targets)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}